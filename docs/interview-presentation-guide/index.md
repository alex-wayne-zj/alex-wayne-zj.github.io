---
title: 面试临场指南
date: 2022-10-18
cover: "./cover.jpg"
tags: 
  - 面试
description: "You are your narrative."
---

对工作的期望：倘若能做成一些有价值的事，结识一些有趣的人，学到一些有趣的知识。这份工作经历就不算浪费生命。

考察要点：技术深度，团队贡献，解决问题的能力，团队协作

自然表达、STAR原则、量化结果、预判追问

## 自我介绍（1min）

姓名，本硕专业学校，研究方向，多端实习经历，多个领域涉猎

主要技术栈，目标岗位相关经历（1-2个项目经历简介）

表达想去公司的意愿，寻找技术上或者业务上的 hook

## 华顺信安

入门 Golang 网络开发和单元测试

1. 用 Golang 实现 BACnet 楼宇控制协议的模拟和解析（解析了超过20个属性，优于nmap），并基于此实现了一个命令行工具，入参包括目标IP、端口、获取信息列表等

   * 比如设备状态、控制命令、事件报警等信息

2. 用 Python 做内部类似nmap工具的 wrapper 包，输入域名或IP，输出到stdout或者XML文件。发布到pypi.org

3. 端口扫描仓库添加4000行+单元测试，使得每个模块单元测试覆盖率超过60%

亮点：了解协议内容 + fofa 查询 IP + go-cobra + wireshark + 网络协议模拟和解析

如何叙述？

我在华顺信安实习时的主要工作是​​提升内部安全扫描工具链的效率和能力​​。

当时，团队需要对楼宇控制网络协议BACnet进行深度检测，但现有的nmap方案在解析深度和灵活性上有所不足。​​我的核心贡献是，独立使用Golang设计并实现了一个高性能的BACnet协议解析与模拟工具。​​主要分为三件事：

第一，我深入研究了BACnet协议规范，用Golang从零构建了协议栈，成功解析了超过20种关键设备属性，比如设备状态和控制命令。为了验证准确性，我频繁使用Wireshark进行抓包对比分析。

第二，我利用go-cobra库将它封装成一个健壮的命令行工具，支持灵活指定目标、端口和要获取的信息列表，使其易于集成到自动化流程中。

第三，为了保障代码质量，我为它所归属的端口扫描核心模块补充了4000多行单元测试，将覆盖率从很低水平提升到60%以上，显著减少了后续开发中的隐性Bug。

总结来说，这个项目不仅让我积累了网络协议开发的实战经验，更让我深刻理解了如何构建一个​​可靠易用​​的后端服务。

## 网心

了解文生图领域的发展情况并实践 Python 后端开发

1. 学习了Stable Diffusion的基本原理，stable-diffusion-webui和comfyui的基本使用

2. 基于 Django 框架和开源 JS 项目 splat 构建 3D 高斯泼溅网页应用，用户可将输入视频转化为 3D 场景

3. 使用 FastAPI 框架搭建 Stable Diffusion LoRA 文生图模型风格微调平台后端。

亮点：学习了Stable Diffusion的基本原理，stable-diffusion-webui和comfyui的基本使用，社区开源项目套壳

如何叙述？

在迅雷的实习中，我的核心任务是​​将前沿的AIGC技术（如Stable Diffusion和3D高斯泼溅）通过后端服务的形式落地，为用户提供可用的AI能力。​​

我主要参与了两项后端开发工作：

​​第一，我负责协助开发了一个Stable Diffusion模型微调平台的后端。​​ 为了快速验证不同LoRA风格模型的效果，我选用了​​FastAPI​​作为核心框架，构建了包括模型加载、异步任务调度、训练状态监控和图片生成在内的全套RESTful API。这个平台成功地将开源模型封装成稳定可调用的服务。

​​第二，我独立使用Django框架构建了一个3D高斯泼溅的网页应用后端。​​ 我整合了前端的Splat开源组件，设计了一套高效的文件上传、视频处理、3D场景生成和结果展示的完整数据流。这个项目考验了我对前后端协同开发的实践。

通过这两个项目，我快速学习并应用了Stable Diffusion等新技术，锻炼了​​将开源算法和研究成果转化为高可用、可扩展的后端服务的能力​​，这包括API设计、异步任务处理和系统集成，这些都是现代后端开发的核心。

## Momenta

沉淀文档（日报/周报），充分沟通

1. 服务管理平台（Service Management System, SMP）前端与后端的需求开发与bug修复
    - GitOps实践，前端 Vue.js + ant-design-vue，后端Gin，底层涉及 Azure Devops、Jenkins CI、Argo CD、Artifactory 和 K8s
    - Infrastructure as Code (K8s manifest) 事件
    - 尝试定义与应用Error Code（业务层面上，方便后端定位问题所在，方便前端了解失败原因，方便实现系统监控）
    - 应用登记页面UI和流程优化，结束后实时返回CD状态（go协程启动第三方服务客户端，time库计时，channel通信，前端得到立刻返回后websocket通信，后端返回信息，使用32位随机ID: channel字典防止并行干扰）登记完发送飞书通知
    - 项目在实现页面query和filter变量ref同步时，由于设置了`<router-view :key="$route.fullPath"></router-view>`，使用router.push()实现，每次都会触发页面created和mounted中的函数，基于history.replaceState()替换当前历史记录条目，从而减少向后端的冗余请求和前端重载次数，显著加速了前端页面的加载速度。并基于此包装实现了页面query和filter同步的组件在其它页面应用
      - 设置 ref 变量watcher，ref变化时history.replaceState()更新path
      - 设置 query watcher，query变化时触发请求函数
    - Make swagger自动化（开发时容易忘记，第三方业务不清楚）：.git/hooks编写pre-commit钩子（可行，但需要团队开发者都添加）
    - 制品镜像页和镜像详情页（主要是go artifactory rest api，以及image相关信息如name, tag, arch, size）
    - 应用环境初始化（K8s api和devops客户端）复杂业务需求调整（配置文件复制改参数注入）
2. Business Intelligence 看板开发
    - 公司自动驾驶算法的数据标注与计算步骤，涉及多个流程，每个流程又有多个任务。在Doris中新建库表，在云端办公机上写Python脚本定时同步各个流程和任务的业务库数据到Doris中，使用Dataease看板或者发送飞书通知来让业务了解流程的执行情况（比如按大小标签划分，处于各个执行状态的流程数量和比例，卡在每个重要任务节点的流程数量等等）
      - 由于使用Python的Schedule库，SQL执行有一定的时间（部分库表更新的数据库量较大），因此不保证定时更新。但和业务沟通过是OK的，他们的需求只是对业务情况的偶尔了解。（业务优先）此外，如果要实现精准的定时任务，当时设想的一种做法是把更新脚本包装成fastapi的接口，通过asyncio异步更新，然后使用公司的一个接口（底层基于K8s的CronJob）定时去调用这个接口去执行。（也类似于AWS的lambda）
      - 由于涉及跨部门协作，期间也是极大地锻炼了自己的沟通能力，owner心态（推动其它业务实现闭环），代码组织能力（一个定时更新数据库脚本，有从ES拿数据的，有从PG拿数据的，数据库字段有JSONB类型需要预处理计算等等）异常处理能力（Doris集群不稳定）
      - 深度使用飞书后，很赞。融合即时沟通、云文档、视频会议以及许多生产力插件。学习了怎么给飞书机器人发卡片通知（甚至还有一个有趣的bug：当时飞书卡片用了柱状图，有一次通知由于图表太多超过20张，导致直接超时发送通知失败了）。
    - partition（按月分片改成按日分片），计算结果表（因为涉及大量计算：如何从json中取字段，比如计算两个时间的差值，比如case when），类似物化视图，查询时间从10秒级优化到秒级
3. 失败的经历：Dataease v1升级v2
    - 能力和精力有限，对Java项目和Spring生态相关技术并没有很高的熟练度；
    - 缺乏技术指导，Mentor太忙，组内无Java专家，几乎单枪匹马；
    - Dataease作为成熟的社区版+企业版项目本身逆向破解难度较高（吃饭的家伙）。
      1. 其实不贵：48000就能永久买断，附带一年专业客服
      2. 暴力修改涉及到的代码太多，需要很久的功能调试时间
      3. 只是实习生性价比较高，万一成功了呢。我也的确通过读代码查到了它引用的两个专门的许可证验证的sdk

亮点：

* 应用登记页面UI和流程优化，结束后实时返回CD状态（go协程启动第三方服务客户端，time库计时，channel通信，前端得到立刻返回后websocket通信，后端返回信息，使用32位随机ID: channel字典防止并行干扰）登记完发送飞书通知
* 项目在实现页面query和filter变量ref同步时，由于设置了`<router-view :key="$route.fullPath"></router-view>`，使用router.push()实现，每次都会触发页面created和mounted中的函数，基于history.replaceState()替换当前历史记录条目，从而减少向后端的冗余请求和前端重载次数，显著加速了前端页面的加载速度。并基于此包装实现了页面query和filter同步的组件在其它页面应用
* 在Doris中新建库表，在云端办公机上写Python脚本定时同步各个流程和任务的业务库数据到Doris中，使用Dataease看板或者发送飞书通知来让业务了解流程的执行情况
* partition（按月分片改成按日分片），计算结果表（因为涉及大量计算：如何从json中取字段，比如计算两个时间的差值，比如case when），类似物化视图，查询时间从10秒级优化到秒级

STAR + 反思收获

优化版（技术挑战+重做反思）

* 需求说明：用户在注册仓库地址、部门、作者、K8s内存、CPU、亲和性等内容后，后台执行初始化注入配置文件，拉起Jenkins CI和ArgoCD流程需要一段时间，此时前段一片空白，用户一直等待，体验极差
* 目标：提交后立刻返回，后台处理，通过WebSocket实时返回进度
* 解决方式：
  1. 原始方式如果挂了会长久等待，拉起协程处理耗时操作，通过timer和context防止超时
  2. 处理并发：传输到channel中供另一个协程通过websocket返回给前端，为了避免并发影响，用sync.Map生成32位独立ID：channel，通过ID识别是哪个客户端
  3. 可靠性：websocket心跳和重连机制，飞书失败超时重试
* 结果：返回速度从十秒级到毫秒级，用户可以查看状态并且离开
* 总结：涉及多并发、同步与异步、Websocket、架构设计等
* 重做：服务器宕机中间状态丢失，过程持久化到Redis或者MySQL中，也方面监控和追踪；异步任务编排、状态管理、实时传输抽象成SDK复用；业务逻辑耦合，可能使用消息队列解耦，重启后任务也不会丢失。

在Momenta实习期间，我主要从事​​中后台系统的后端开发与性能优化工作​​。

我重点想分享三个有代表性的贡献：

​​第一，是深度参与了一个基于GitOps的云原生应用管理平台的建设。​​ 我使用Gin框架进行后端开发，核心负责了‘应用登记’这个关键流程。为了优化用户体验，我设计了一个​​异步任务处理机制​​：当用户提交申请后，后端会立即返回成功状态，同时通过Go协程在后台真正执行复杂的CI/CD流水线初始化。前端通过WebSocket实时获取进度。这个设计涉及协程、Channel通信和状态管理，​​成功将前端等待时间从分钟级降到了秒级以内​​，并保证了系统在高并发下的稳定性。

​​第二，我主导了一个业务智能看板的数据管道构建。​​ 为了监控公司核心算法数据的处理流程，我独立负责了从零到一的数据同步任务。我编写Python脚本，定期从多个业务数据库（如PostgreSQL、Elasticsearch）中抽取、转换并同步数据到Doris中，并基于此构建可视化看板。过程中，我通过优化数据表的分区策略和预计算关键指标，​​将关键查询的响应时间从10秒级优化到了秒级​​，极大地提升了业务决策的效率。

​​第三，我非常注重工程质量和团队协作。​​ 例如，我推动并实践了​​错误码规范​​，统一了前后端及监控系统的异常处理逻辑；我还通过Git钩子自动化Swagger文档生成，提升团队协作效率。

这段经历让我对中大型后端系统的开发、数据管道处理和性能优化有了深入的实战经验。

## 腾讯

迅速 landing，积极沟通，对新技术保持好奇

1. 在熟悉公司环境、配置开发容器及其依赖环境后，我便开始阅读后端仓库代码与微服务tRPC框架文档，通过以下两个具体的开发工作熟悉部门开发相关平台（低代码配置管理平台，devops 平台，打包工具，可观测平台等）实现迅速landing

    * 小宝对话框上传文件（image/file）根据文件类型返回推荐提示词，
    * 将Deepseek对话服务提供方从腾讯云迁移到太极

2. 从0到1梳理后台应用的线上SRE伽利略监控：包括但不限于主调监控、被调监控、事件监控等。对照阅读ai_tool源码，梳理对外接口提供的功能

3. 实现LLM调用MCP工具推荐论文

4. 内容工作流节点开发：通过小红书、B站等的AI工作流介绍视频 / 图文链接，自动拆解工作流

    * 基于算法提供能力解析图文URL和视频URL的文本和图像内容
    * 接入hunyuan-turbo和hunyuan-vision模型分析文本和视觉内容
    * 通过无极平台管理不同步骤的prompt提示词模板
    * 为KOL生成唯一邀请码并验证邀请码是否有效

亮点：

* 内容工作流节点开发：通过小红书、B站等的AI工作流介绍视频 / 图文链接，自动拆解工作流：基于算法提供能力解析图文URL和视频URL的文本和图像内容，接入hunyuan-turbo和hunyuan-vision模型分析文本和视觉内容，通过无极平台管理不同步骤的prompt提示词模板，为KOL生成唯一邀请码并验证邀请码是否有效
* 实现LLM调用MCP工具推荐论文：不提供 go-sdk，主动找工蜂内部开发团队
* 小难点：内部框架、工具和流程文档化做的一般，多问多学
* 小难点：一直的跑的 golang 协程，第三方服务不稳定，没有接收 Context 的 Done 信号

在腾讯实习期间，我主要负责AI应用平台的后端开发工作。我主要想分享三个方面的贡献：

​​第一，我参与了一个‘内容工作流解析节点’的设计与实现。​​ 这个功能的业务目标是自动化解析小红书、B站等平台上的AI工作流。我负责其中若干的模块的开发工作​：调用算法服务解析图文/视频URL抽取内容，接入腾讯自研的hunyuan大模型进行多模态内容理解，通过低代码平台动态管理提示词模板等等，赋能用户AI能力​​。

​​第二，我从零构建了后台应用的线上SRE监控体系。​​ 我深入调研业务代码，在内部可观测平台上​​梳理并配置了包括主调监控、被调监控、事件监控在内的全套可观测性方案​​，为服务的稳定性和可排查性打下了坚实基础。

​​第三，我展现了技术攻关和跨团队协作能力。​​ 例如，在实现‘LLM调用MCP工具推荐论文’ feature时，由于官方未提供Go-SDK，我主动寻找到内部开发团队并推动协作，​​最终通过阅读源码和沟通，成功完成了集成​​，保证了项目进度。

这段在腾讯的实习，让我在​​大型微服务架构下的后端开发、AI工程化落地和系统可观测性建设​​方面获得了宝贵的实战经验。

## 面试官 Q&A

前期：

1. 部门主要业务和技术栈？
2. 可选 Base 地？
3. 你觉得我今天的表现如何，有哪些需要改进的地方？
4. AI时代和Google时代的异同点，对与初期工程师有什么建议？（被冲击得最厉害）

后期：
1. 实习生培训机制？
2. 部门团队氛围以及同事是否有趣？
3. 如何看待线上技术笔试和面试作弊，有人辅助的情况相对容易。力扣和面经是有标准答案的，通过AI很容易找到，技术面试官过分看重这些可量化的东西，导致内卷或者劣币驱逐良币。我实际的实习经验告诉我，技术岗在初期只需要对各个领域（数据库、业务、中间件等）有所了解，在具体工作时深入了解即能胜任。此外，日常工作中技术可能只占60%，其它重要的部分包括沟通与表达能力，做事靠谱程度，与全队的配合程度等，则并没有被很好的考察。

## 职业规划

技术开发，而非算法研究，但需要关注

技术栈

- Vue
- Golang
- Python
- K8s
- AI

需要选择一项深入探索的技术，成为专家

## 字节三面个人介绍优化

面试官您好，我叫张健，目前是北京航空航天大学计算机学院的硕士，研究方向是计算机视觉的视频动作识别。本科同样在北航软件工程专业，本硕期间系统学习了软件工程、计算机网络、操作系统、数据库原理等课程。

我过去在多家公司有后端开发实习经历，主要使用Golang完成业务与平台系统开发。

在腾讯实习期间，我负责应用宝PC端AI助手后台服务的开发与上线，后端为Golang为服务架构。同时完善了SRE可观测性监控，包括主调、被调和事件的监控埋点。这段经历让我了解了SRE相关知识。

在Momenta实习时，我参与了公司内部服务管理平台的全栈开发与维护。该平台面向内部开发者完成从代码拉取、打包、测试、CI、CD上线等流程。这让我熟悉了系统运维的完整链路。

此外，我在迅雷实习和研究生项目时也参与了AI项目的搭建，对AI相关知识有系统深入的学习

综合来看，我的经验涵盖了Golang后端开发、SRE运维系统建设、视频业务、AI开发等方面，与贵部门AI运维平台后端开发方向非常契合。我非常希望有机会加入贵公司，在实际场景中继续深化对大规模服务稳定性与智能运维的理解与实践。